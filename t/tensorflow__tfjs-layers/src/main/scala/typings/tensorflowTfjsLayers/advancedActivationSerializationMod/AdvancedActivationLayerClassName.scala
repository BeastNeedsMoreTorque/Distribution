package typings.tensorflowTfjsLayers.advancedActivationSerializationMod

import scala.scalajs.js
import scala.scalajs.js.`|`
import scala.scalajs.js.annotation._

/* Inlined @tensorflow/tfjs-layers.@tensorflow/tfjs-layers/dist/keras_format/layers/advanced_activation_serialization.AdvancedActivationLayerSerialization['class_name'] */
/* Rewritten from type alias, can be one of: 
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.PReLU
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ThresholdedReLU
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ELU
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ReLU
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.Softmax
  - typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.LeakyReLU
*/
trait AdvancedActivationLayerClassName extends js.Object

object AdvancedActivationLayerClassName {
  @scala.inline
  def ELU: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ELU = this.cast("ELU")
  @scala.inline
  def LeakyReLU: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.LeakyReLU = this.cast("LeakyReLU")
  @scala.inline
  def PReLU: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.PReLU = this.cast("PReLU")
  @scala.inline
  def ReLU: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ReLU = this.cast("ReLU")
  @scala.inline
  def Softmax: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.Softmax = this.cast("Softmax")
  @scala.inline
  def ThresholdedReLU: typings.tensorflowTfjsLayers.tensorflowTfjsLayersStrings.ThresholdedReLU = this.cast("ThresholdedReLU")
  @scala.inline
  /* private */ def cast[T](in: js.Any): T = in.asInstanceOf[T]
}

